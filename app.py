import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader
from gtts import gTTS
import os
import io
import PIL.Image
import json

# --- 1. ç³»çµ±åˆå§‹åŒ– (ä½¿ç”¨æœ€æ–°çš„ Secrets è®€å–æ–¹å¼) ---
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=API_KEY)
except Exception as e:
    st.error("âŒ æ‰¾ä¸åˆ° API é‡‘é‘°ï¼Œè«‹æª¢æŸ¥ Streamlit Secrets è¨­å®šã€‚")
    st.stop()

st.set_page_config(page_title="è€é·¹ AI é•·æœŸåŠ©ç†", layout="wide")

# ä½¿ç”¨ç©©å®šç‰ˆçš„æ¨¡å‹åç¨±æ ¼å¼
MODEL_NAME = 'gemini-1.5-flash'
# åˆå§‹åŒ–æ¨¡å‹
try:
    model = genai.GenerativeModel(model_name=MODEL_NAME)
except Exception as e:
    st.error(f"âŒ ç„¡æ³•è®€å–æ¨¡å‹ {MODEL_NAME}ï¼ŒéŒ¯èª¤å…§å®¹: {e}")
    st.stop()

# --- 2. è¨˜æ†¶åŠŸèƒ½ (JSON å„²å­˜) ---
HISTORY_FILE = "chat_history.json"

def load_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return []
    return []

def save_history(history):
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

if "messages" not in st.session_state:
    st.session_state.messages = load_history()

# --- 3. ä»‹é¢è¨­è¨ˆ ---
st.title("ğŸ¦… è€é·¹åœ˜éšŠï¼šé•·æœŸ AI æ™ºæ…§åŠ©ç†")

with st.sidebar:
    st.header("âš™ï¸ åŠ©ç†ç®¡ç†")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰å°è©±ç´€éŒ„"):
        st.session_state.messages = []
        save_history([])
        st.rerun()
    
    st.divider()
    uploaded_pdf = st.file_uploader("ä¸Šå‚³åŸ¹è¨“æ•™æ (PDF)", type="pdf")
    uploaded_image = st.file_uploader("ä¸Šå‚³å°è©±æˆªåœ– (åˆ†æç”¨)", type=["png", "jpg", "jpeg"])

# è™•ç† PDF
context_text = ""
if uploaded_pdf:
    try:
        reader = PdfReader(uploaded_pdf)
        for page in reader.pages:
            context_text += page.extract_text() + "\n"
        st.sidebar.success("âœ… æ•™æå·²è¼‰å…¥")
    except Exception as e:
        st.sidebar.error(f"PDF è®€å–å¤±æ•—: {e}")

# é¡¯ç¤ºæ­·å²ç´€éŒ„
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 4. å•ç­”é‚è¼¯ ---
if prompt := st.chat_input("è«‹å•å°å¸«..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    
    content_list = []
    if uploaded_image:
        try:
            img = PIL.Image.open(uploaded_image)
            content_list.append(img)
        except:
            st.error("åœ–ç‰‡æ ¼å¼éŒ¯èª¤")

    # çµ„åˆè„ˆçµ¡
    history_context = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages[-3:]])
    full_prompt = f"ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è€é·¹åœ˜éšŠå°å¸«ã€‚æ•™æèƒŒæ™¯ï¼š\n{context_text[:5000]}\nè¿‘æœŸå°è©±ï¼š\n{history_context}\nç¾åœ¨å•é¡Œï¼š{prompt}"
    content_list.append(full_prompt)

    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            try:
                # æ ¸å¿ƒèª¿ç”¨è™•
                response = model.generate_content(content_list)
                full_response = response.text
                st.markdown(full_response)
                
                # èªéŸ³ç”Ÿæˆ
                tts = gTTS(text=full_response[:150], lang='zh-tw')
                audio_fp = io.BytesIO()
                tts.write_to_fp(audio_fp)
                st.audio(audio_fp, format='audio/mp3')

                # å„²å­˜å°è©±
                st.session_state.messages.append({"role": "user", "content": prompt})
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                save_history(st.session_state.messages)
            except Exception as e:
                st.error(f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤: {e}")
                st.info("è«‹ç¢ºèªæ‚¨çš„ API é‡‘é‘°æ˜¯å¦æœ‰æ•ˆï¼Œä»¥åŠè©²æ¨¡å‹æ˜¯å¦æ”¯æ´æ‚¨çš„æ‰€åœ¨åœ°å€ã€‚")
