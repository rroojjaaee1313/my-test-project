import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader
from gtts import gTTS
import os
import io
import PIL.Image
import json

# 1. ç³»çµ±åˆå§‹åŒ–èˆ‡é‡‘é‘°
API_KEY = "AIzaSyCALV4Zyjpc5h5_7DJpy-OXha19QTVXbIE"
genai.configure(api_key=API_KEY)
st.set_page_config(page_title="è€é·¹ AI é•·æœŸåŠ©ç†", layout="wide")

# åˆå§‹åŒ–æ¨¡å‹
model = genai.GenerativeModel('models/gemini-1.5-flash')

# --- è¨˜æ†¶åŠŸèƒ½ï¼šè®€å–èˆ‡å„²å­˜ JSON æª”æ¡ˆ ---
HISTORY_FILE = "chat_history.json"

def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_history(history):
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

# åˆå§‹åŒ– Session State ä¸­çš„å°è©±ç´€éŒ„
if "messages" not in st.session_state:
    st.session_state.messages = load_history()

# --- ä»‹é¢è¨­è¨ˆ ---
st.title("ğŸ¦… è€é·¹åœ˜éšŠï¼šé•·æœŸ AI æ™ºæ…§åŠ©ç†")

with st.sidebar:
    st.header("âš™ï¸ åŠ©ç†ç®¡ç†")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰å°è©±ç´€éŒ„"):
        st.session_state.messages = []
        save_history([])
        st.rerun()
    
    st.divider()
    uploaded_pdf = st.file_uploader("ä¸Šå‚³åŸ¹è¨“æ•™æ (PDF)", type="pdf")
    uploaded_image = st.file_uploader("ä¸Šå‚³å°è©±æˆªåœ– (åˆ†æç”¨)", type=["png", "jpg", "jpeg"])

# è™•ç† PDF çŸ¥è­˜åº«
context_text = ""
if uploaded_pdf:
    reader = PdfReader(uploaded_pdf)
    for page in reader.pages:
        context_text += page.extract_text() + "\n"

# --- é¡¯ç¤ºæ­·å²å°è©±ç´€éŒ„ ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- ä½¿ç”¨è€…è¼¸å…¥å€ (Chat Input) ---
if prompt := st.chat_input("è«‹å•å°å¸«..."):
    # 1. é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # 2. æº–å‚™åˆ†æå…§å®¹
    content_list = []
    if uploaded_image:
        img = PIL.Image.open(uploaded_image)
        content_list.append(img)
    
    # åŠ å…¥æ•™æèƒŒæ™¯èˆ‡æ­·å²ç´€éŒ„çš„è„ˆçµ¡
    history_context = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages[-5:]]) # åªå–æœ€è¿‘5å‰‡
    full_prompt = f"ä½ æ˜¯è€é·¹åœ˜éšŠå°å¸«ã€‚æ•™æå…§å®¹ï¼š\n{context_text[:5000]}\nè¿‘æœŸå°è©±ï¼š\n{history_context}\nç¾åœ¨å•é¡Œï¼š{prompt}"
    content_list.append(full_prompt)

    # 3. ç²å– AI å›è¦†
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            response = model.generate_content(content_list)
            full_response = response.text
            st.markdown(full_response)
            
            # ç”ŸæˆèªéŸ³æŒ‰éˆ•
            tts = gTTS(text=full_response[:200], lang='zh-tw') # å–å‰200å­—ç”ŸæˆèªéŸ³é¿å…éé•·
            audio_fp = io.BytesIO()
            tts.write_to_fp(audio_fp)
            st.audio(audio_fp, format='audio/mp3')

    # 4. å­˜å…¥è¨˜æ†¶
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.messages.append({"role": "assistant", "content": full_response})
    save_history(st.session_state.messages)
